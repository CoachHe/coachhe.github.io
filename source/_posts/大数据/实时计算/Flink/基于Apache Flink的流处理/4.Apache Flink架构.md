---
title: 4.Apache Flink架构  
date: 2022-12-04 02:12:43  
tags: []  
categories:
  - 大数据
  - 实时计算
  - Flink
  - 基于Apache Flink的流处理
---

# 系统架构

Flink是一个用于**状态化流处理的分布式系统**。它的搭建射击多个进程，这些进程通常会分布在多台机器上。

## 分布式系统需要应对的常见挑战

Flink并没有依靠自身实现所有分布式系统需要解决的问题，而是在已有集群基础设施和服务之上专注于它的核心功能。

1. 分配和管理集群计算资源

   Flink自身可以实现

2. 进程协调

   Flink自身可以实现

3. 持久且**高可用**的**数据存储**以及**故障恢复**等

   1. Flink没有提供分布式持久化存储，而是利用了现有的分布式文件系统（如HDFS）或对象存储（如S3）。
   2. 它依赖Apache Zookeeper来完成高可用设置中的领导选举工作。

# 搭建Flink所需组件

Flink搭建需要四个不同组件。

<img src="https://coachhe-1305181419.cos.ap-guangzhou.myqcloud.com/程序员/工具/git/20221121005414.png" width = "50%" />

## 作业管理器（JobManager）


- 控制一个应用程序执行的主进程，也就是说，每个应用程序都会被一个不同的 JobManager 所控制执行
- JobManager 会先接收到要执行的应用程序，这个应用程序会包括：作业图 （JobGraph），即逻辑Dataflow图和打包了所有的类、 库和其它资源的JAR包。
- JobManager 会把JobGraph转换成一个物理层面的数据流图，这个图被叫做“执行图”（ExecutionGraph），包含了所有可以并发执行的任务。
- JobManager 会向资源管理器（ResourceManager）请求执行任务必要的资源， 也就是任务管理器（TaskManager）上的插槽（slot）。一旦它获取到了足够的资源，就会将执行图分发到真正运行它们的TaskManager上。而在运行过程中， JobManager会负责所有需要中央协调的操作，比如说检查点（checkpoints）的协调。

### JobManager 最重要的三个组件

#### 1. JobMaster

- `JobMaster` 是 `JobManager` 中最核心的组件，负责处理单独的作业。

- 在作业提交时， `JobManager` 会最先接收到要执行的应用，一般是由客户端提交来的，包括：`Jar` 包，数据流图（`dataflow graph`）和作业图（`JobGraph`）。

- `JobMaster` 会把 `JobGraph` 转换成一个物理层面的数据流图，这个图被称为执行图（`ExecutionGraph`），它包含所有并发执行的任务。`JobMaster` 会向资源管理器（`Resource Manager`）发出请求，申请执行任务的必要资源。一旦它获取到了足够资源，就会将执行图分发到真正运行它们的 `TaskManager` 上。

- 在运行过程中，`JobMaster` 会负责所有需要中央协调的操作，比如检查点（`checkpoints`）的协调。

#### 2. 资源管理器（ResourceManager）

- 主要负责管理任务管理器（`TaskManager`）的插槽（`slot`），`TaskManger` 插槽是 `Flink` 中定义的处理资源单元。

- Flink为不同的环境和资源管理工具提供了不同资源管理器，比如`YARN`、`Mesos`、`K8s`，以及`standalone`部署。

- 当 `JobManager` 申请插槽资源时，`ResourceManager` 会将有空闲插槽的 `TaskManager` 分配给 `JobManager` 。如果 `ResourceManager` 没有足够的插槽来满足 `JobManager` 的请求，它还可以向资源提供平台发起会话，以提供启动 
 `TaskManager` 进程的容器。

#### 3. 分发器（Dispatcher）

- 可以跨作业运行，它为应用提交提供了REST接口。

- 当一个应用被提交执行时，分发器就会启动并将应用移交给一个`JobManager`。

- `Dispatcher`也会启动一个`Web UI`，用来方便地展示和监控作业执行的信息。

- `Dispatcher`在架构中可能并不是必需的，这取决于应用提交运行的方式。



## 任务管理器（TaskManager）

- `Flink`中的工作进程。通常在Flink中会有多个 `TaskManager` 运行，每一个 `TaskManager` 都包含了一定数量的插槽（`slots`）。插槽的数量限制了 `TaskManager` 能够执行的任务数量。

  **注意：`TaskManager` 数量与插槽总数的乘积就是集群静态的并行计算的能力。**

- 启动之后， `TaskManager` 会向资源管理器注册它的插槽；收到资源管理器的指令后， `TaskManager` 就会将一个或者多个插槽提供给J `JobManager` 调用。Jo `JobManager` 就可以向插槽分配任务（`tasks`）来执行了。

- 在执行过程中，一个 `TaskManager` 可以跟其它运行同一应用程序的 `TaskManager` 交换数据。




# 应用提交执行过程中Flink各组件之间的交互过程

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201214152703.png" style="zoom: 67%;" />

### Standalone模式下作业提交流程

<img src="https://coachhe-1305181419.cos.ap-guangzhou.myqcloud.com/程序员/工具/git/20221121011451.png" width = "50%" />

### 在YARN模式下应用提交流程

#### session mode

<img src="https://coachhe-1305181419.cos.ap-guangzhou.myqcloud.com/程序员/工具/git/20221121011647.png" width = "50%" />

一开始只有 `JobManager`

#### 单作业模式

<img src="https://coachhe-1305181419.cos.ap-guangzhou.myqcloud.com/程序员/工具/git/20221121012006.png" width = "50%" />








<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201214170015.png" style="zoom: 67%;" />



# 任务调度原理

## 任务的概念

任务是最小单位，任务数量$=$算子$\times$ 并行度，当算子并行度为1时，任务数量就是算子数量。

任务是构成slot的部分。



任务提交的主要工作就是将任务给到JobManager，JobManager需要进行进一步的处理，这个就是任务调度。

![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210222085003.png)

上图介绍了从code（程序）到最后的Task的过程。 

## 并行度

**定义**：一个特定算子的子任务（subtask）的个数被称之为其并行度。一般情况下，一个stream的并行度，可以认为就是其所有算子中最大的并行度。

![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210222091736.png)

以source为例，设置并行度为2，代表Souce会有两个并行的子任务，Sink的并行度为1，因为只有一个子任务，所有按照最大的并行子任务来计算，Stream的并行度为2。

最后可以合并：(参照下面的任务链接)

![](https://coachhe-1305181419.cos.ap-guangzhou.myqcloud.com/%E7%A8%8B%E5%BA%8F%E5%91%98/%E5%B7%A5%E5%85%B7/git/20221124005223.png)



### 并行度设置

```java
.setParallelism(2)
```

## TaskManager和Slots

`Slot` 是指 `TaskManager` 具有的并行执行程序

![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210222165915.png)

* Flink中每一个TaskManager都是一个JVM进程，它可能会在独立的线程上执行一个或多个任务
* 为了控制一个TaskManager能接收多少个task，TaskManager通过task slot来进行控制（一个TaskManager至少有一个slot）
* 简单来说，线程所占据的资源就是slot

![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210222161633.png)

* 默认情况下，Flink允许子任务共享slot，即使它们是不同任务的子任务。这样的结果是，一个slot可以保存作业的整个管道。

  也就是说，一个slot代表一个作业的一类操作，整个作业的管道就在这里保存。

  **注意**：管道就是整个处理流程的每一步操作（一整套计算流程）

* Task Slot是静态的概念，是指TaskManager具有的并发执行能力。

### 任务共享Slot

- 默认情况下，`Flink` 允许子任务共享 `slot` 。这样的结果是，一个 `slot` 可以保存作业的整个管道
- 当我们讲资源密集型和非密集型的任务同时放到一个 `slot` 中，它们就可以自行分配对资源占用的比例，从而保证最重的活平均分配给所有的 `TaskManager`。


### 总结

一个JobGraph可以转换为多个TaskManager，每个TaskManager由不同的slot构成，一个slot对应一个任务。

## 并行子任务的分配

![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210222170745.png)

原则是尽量保证每个slot任务均衡

## 高可用性设置

高可用性分为两部分，分别是TaskManager故障和JobManager故障

1. TaskManager故障

   如果TaskManager出现故常，则可用的slot数量减少，此时JobManager就会向ResourceManager申请更多的slot，如果无法完成，JobManager将无法重启应用，直至有足够数量的可用slot。

2. JobManager故障

   JobManager在高可用模式下工作时，会将JobGraph以及全部所需的元数据（例如所写的JAR文件）写入一个远程持久化存储系统（例如HDFS）中。此外，JobManager还会将存储位置的路径地址写入ZooKeeper的数据存储。

   如图所示：

   <img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210222174727.png" style="zoom: 25%;" />

   当JobManager发生故障时，其下应用的所有任务都会自动取消，新接手的JobManager会执行以下步骤：

   1. 向ZooKeeper请求存储位置，以获取JobGraph、JAR文件以及应用最新检查点在远程存储的状态句柄
   2. 向ResourceManager申请处理槽来继续执行应用
   3. 重启应用并利用最近一次检查点充值任务状态

## Flink中的数据传输

### 数据传输形式

1. `one-to-one`： 这意味着map算子的子任务看到的元素的个数以及顺序跟 source 算子的子任务生产的元素的个数、顺序相同。`map`, `filter`, `flatMap` 等算子都是 `one-to-one` 的对应关系。
2. `Redistributing`： stream 的分区会发生改变。每个算子的子任务依赖所选择的 transformation 发送数据到不同的目标任务。 例如，keyBy基于 hashCode 重分区、而broadcast 和 rebalance 会随机重新分区，这些算子都会引起 `redistribute` 过程，而 `redistribute` 过程就类似于 `Spark` 中的 `shuffle` 过程

在运行过程中，应用的任务会持续进行数据交换。TaskManager负责将数据从发送任务传输至接收任务。它的网络模块在记录传输前会先将它们收集到缓冲区中。

换言之，**记录并非逐个发送的，而是在缓冲区中以批次形式发送**。

#### 注意

将记录放入缓冲区并不意味着Flink的处理模型是基于微批次的。

#### 问题

通过网络连接逐条发送记录不但低效，还会导致很多额外开销。若想充分利用网络连接带宽，就需要对数据进行缓冲。在流处理环境下，缓冲的一个明显缺点是会增加延迟，因为记录首先要收集到缓冲区中而不会立即发送。

### 基于信用值的流量控制

#### 工作原理

接收任务会给发送任务授予一定的信用值，其实就是保留一些用来接收它数据的网络缓冲。一旦发送端收到信用通知，就会在信用值所限定的范围内尽可能多地传输缓冲数据，并会附带上积压量（已经填满准备传输的网络缓冲数目）大小。
接收端使用保留的缓冲来处理收到的数据，同时依据各发送端的积压量信息来计算所有相连的发送端在下一轮的信用优先级。

#### 优点

发送端可以在接收端有足够资源时立即传输数据，所以基于信用值的流量控制可以有效降低延迟。此外，信用值的授予是根据各发送端的数据积压量来完成的，因此该机制还能在出现数据倾斜（data skew）时有效地分配网络资源。

### 任务链接（算子链）

Flink采用一种名为**任务链接**的优化技术来降低某些情况下的本地通信开销。

#### 前提条件

多个算子必须有**相同的并行度**且通过**本地转发通道**（local forward channel）相连。

#### 示例

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210223021122.png" style="zoom: 33%;" />

可以看到，图中所有算子的并行度相同并且通过本地转发通道相连，因此可以将三个算子进行“融合”，在单线程中进行执行，并且通过方法调用进行数据传输。也就是说，不同函数之间直接可以调用也避免了tcp连接。

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210223021239.png" style="zoom: 33%;" />

虽然任务链接可以有效地降低本地任务之间的通信开销，但有的流水线应用反而不希望应用到它。例如有时候我们需要对过长任务连接进行切分或者将两个计算量大的函数分配到不同处理槽中。

#### 分配到不同处理槽的方法

disableChaining()方法

结果就是每个函数都交由单独的任务、在特定线程内处理。

也可以用startNewChain()方法开始新的任务链

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210223022633.png" style="zoom: 33%;" />









