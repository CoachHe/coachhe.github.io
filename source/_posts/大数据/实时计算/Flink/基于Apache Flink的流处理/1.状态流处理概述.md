---
title: 1.状态流处理概述  
date: 2022-12-04 02:11:25  
tags: []  
categories:
  - 大数据
  - 实时计算
  - Flink
  - 基于Apache Flink的流处理
---

# 事务型处理

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211170831.png" style="zoom: 33%;" />

在事务型处理问题时，多个应用会共享同一个数据库系统，有时候还会访问相同的数据库或表。

## 问题
一旦多个而应用基于相同的数据表示或共享架构，那么更改表模式或对数据库系统进行扩缩容必将劳心费力。

# 分析型处理

```mermaid
graph LR
事务性-->分析型
```

## 原因
如果能将不同事务型数据库的内容进行联合查询，能为企业提供更加全面的分析见解。然而事务型数据库之间通常相互隔离，难以联合分析，因此将其**全部导入一个数据仓库中**，就可以进行联合查询，创造更高价值。


## 分析型数据库操作
对于分析类查询，我们通常不会直接在事务型数据库上执行，而是将数据复制到一个专门用来处理分析类查询的**数据仓库**。

### 数据仓库怎么来
为了填充数据仓库，需要将事务性数据库系统中的数据拷贝过去。这个向数据仓库拷贝数据的过程被称为提取-转换-加载（Extract-Transform-Load，**ETL**）。

#### ETL基本流程
从事务型数据库中提取数据，将其转换为通用表示形式，最终加载到分析型数据库（数据仓库）中。  
并且为了保证数据同步，ETL需要周期性执行。

### 用于数据分析的传统数仓架构

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211190414.png" style="zoom: 33%;" />

如图所示，对数据仓库的查询分析有两种  
1. **定期报告查询**
  可用于计算业务相关的统计数据，如收入等。将这些指标整合成报告，能够帮助管理层评估企业整体健康状况。

2. **即席查询**  

  主要目的是通过解答特定问题来辅助关键性的商业决策，例如通过查询来整合应收数字和电台广告中的投入，以评估市场营销的有效性。

# 状态化流处理
## 原因
几乎所有数据都是以连续时间流的形式产生。

## 有状态定义
有状态的定义是能够存储和访问中间结果。任何一个处理事件流的应用，如果要支持跨多条记录的转换操作，都必须是有状态的。

## Flink应用状态存储方式
Apache Flink会将应用状态存储在本地内存或嵌入式数据库中。由于采用的是分布式架构，Flink需要对本地状态予以保护。以避免因应用或机器故障导致数据丢失。

### 本地状态保护方式
Flink会定期将应用状态的一致性检查点（checkpoint）写入远程持久化存储。

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211190506.png" style="zoom:33%;" />

## 有状态的流处理应用读取事件记录的方式
有状态的流处理应用通常会从事件日志中读取事件记录。

事件日志负责**存储事件流并将其分布式化**。

## 三种常见有状态流处理应用

### ① 事件驱动型应用

#### 定义
事件驱动型应用是一类通过接收事件流触发特定应用业务逻辑的有状态的流式应用

#### 典型应用场景
1. 实时推荐
2. 模式识别或复杂事件处理
3. 异常监控  

事件驱动型应用利用日志进行通信，其数据则会以**本地状态形式**存储。

#### 优势
1. 访问本地状态的性能比读写远程数据存储系统更好  
也就是说，其数据存储在本地（通过checkpoint和远程同步），对某些事件的反应（例如异常监控）时不需要访问远程数据库，从而速度快很多。
2. 伸缩和容错交由流引擎完成
3. 以事件日志作为应用的输入，完整可靠，还支持精准的数据重放

### ② 数据管道

#### 场景
公司为了提高数据访问性能把相同数据存储到多个系统。  
例如网点内的某产品信息会同时放在事务型数据库、网站缓存以及搜索引擎中。  

#### 原因
数据存在多个副本，这些数据存储系统之间需要保持同步。

#### 同步方式
使用事件日志系统来分发更新。具体来说就是将更新写入时间日志系统，并由它进行分发。


### ③ 流式分析
#### 应用场景
1. 手机网络质量监控
2. 移动应用中的用户行为分析
3. 消费者技术中的实时数据即席分析

# 开源流处理的演变

## 第1代流引擎（Storm）
典型代表就是Storm，并未针对流式应用的结果的准确性和一致性提供内置保障，结果完全取决于事件到达的时间和顺序。  
此外，虽然数据在出错时不会丢失，但可能被处理多次。

## 第2代流引擎（Lambda架构）
<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211190556.png" style="zoom:33%;" />

### 思路
用两套系统，同时保证低延迟和结果准确。  
在传统周期性批处理架构的基础上添加了一个由低延迟流处理引擎所驱动的“提速层”。  
最终将两层的结果进行合并。

### 第3带流引擎（Flink）
解决了时间顺序问题。  
无需让用户在延迟和吞吐量之间做出困难的抉择。

# Flink初体验

1. 安装Flink（第3章会介绍）

2. 启动本地集群

   在这里我们采用的是群起集群，具体配置和方式会在后面进行介绍

   <img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211191810.png" style="zoom:25%;" />

3. 下载示例JAR文件

   ```shell
   wget https://streaming-with-flink.github.io/examples/download/examples-scala.jar
   ```

4. 通过指定应用的入口类和JAR文件，在集群上运行示例。

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211192437.png" style="zoom: 50%;" />

5. 可以看到，在Web UI会看到“Running Jobs"列表中有一个作业。

   ![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211192625.png)

   单击那个作业，可以看到下图所示的数据流程及运行作业中算子的实时指标。

   ![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211195101.png)

6. 作业的输出会写入Flink工作流程的标准输出，默认情况下它会重定向到./logs目录下的文件

   可以使用tail命令监控持续产生的结果。

   ```shell
   tail -f flink-coachhe-taskexecutor-0-hadoop100.out
   ```

7. 由于应用是流式的，它会一直运行下去，直到手动取消。取消的方式是在Web UI中选中作业，然后单击页面上方的Cancel按钮。

   ![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211194318.png)

8. 最后别忘了停止本地Flink集群

   <img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Flink/20201211194426.png" style="zoom:50%;" />

# 批处理WordCount

## 1. 首先建立一个Maven项目

## pom.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>

<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0
http://maven.apache.org/xsd/maven-4.0.0.xsd">

    <modelVersion>4.0.0</modelVersion>
    <groupId>com.atguigu.flink</groupId>
    <artifactId>FlinkTutorial</artifactId>
    <version>1.0-SNAPSHOT</version>
    <dependencies>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-scala_2.12</artifactId>
            <version>1.10.1</version>
        </dependency>
        <!-- https://mvnrepository.com/artifact/org.apache.flink/flink-streaming-scala -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-scala_2.12</artifactId>
            <version>1.10.1</version>
        </dependency>
    </dependencies>
    <build>
        <plugins>
            <!-- 该插件用于将 Scala 代码编译成 class 文件 -->
            <plugin>
                <groupId>net.alchim31.maven</groupId>
                <artifactId>scala-maven-plugin</artifactId>
                <version>3.4.6</version>
                <executions>
                    <execution>
                        <!-- 声明绑定到 maven 的 compile 阶段 -->
                        <goals>
                            <goal>compile</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-assembly-plugin</artifactId>
                <version>3.0.0</version>
                <configuration>
                    <descriptorRefs>
                        <descriptorRef>jar-with-dependencies</descriptorRef>
                    </descriptorRefs>
                </configuration>
                <executions>
                    <execution>
                        <id>make-assembly</id>
                        <phase>package</phase>
                        <goals>
                            <goal>single</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>
```

## 2. 在src下创建scala目录并标志为Sources Root，准备文件

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210129032337.png" style="zoom: 33%;" />

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210129034938.png" style="zoom:33%;" />



## 3. 编写程序

```scala
package com.coachhe.wc

import org.apache.flink.api.scala.ExecutionEnvironment
import org.apache.flink.api.scala._

// 批处理wordcount
object WordCount {
  def main(args: Array[String]): Unit = {
    // 1. 创建一个批处理执行环境
    val env: ExecutionEnvironment = ExecutionEnvironment.getExecutionEnvironment

    // 2. 从文件中读取数据
    val inputPath: String = "/Users/heyizhi/Nutstore Files/我的坚果云/程序员/学习/大数据/10 flink/1st flink project/flinkTutorial/src/main/resources/hello.txt"
    val inputDataSet: DataSet[String] = env.readTextFile(inputPath)

    // 3. 对数据进行转换处理统计，先分词，再按照word进行分组，最后进行聚合统计
    val resultDataSet: DataSet[(String, Int)] = inputDataSet
      .flatMap(_.split(" "))
      .map((_, 1))
      .groupBy(0) // 以第一个元素作为key，进行分组
      .sum(1) // 对当前分组的所有数据的第2个元素求和


    // 4. 打印输出
    resultDataSet.print()
  }

}
```

## 4. 运行

<img src="https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210129035014.png" style="zoom:33%;" />

# 流处理WordCount



## 代码

```java
package com.coachhe.wc

import org.apache.flink.streaming.api.scala._

// 流处理WordCount
object StreamWordCount {
  def main(args: Array[String]): Unit = {
    // 1. 创建流处理执行环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

    // 2. 接收一个socket文本流
    val inputDataStream: DataStream[String] = env.socketTextStream("localhost", 7777)

    // 3. 进行转化处理统计
    val resultDataStream: DataStream[(String, Int)] = inputDataStream
      .flatMap(_.split(" "))
      .filter(_.nonEmpty)
      .map((_, 1))
      .keyBy(0)
      .sum(1)

    // 4. 打印输出
    resultDataStream.print()

    // 5. 启动任务执行（调用环境）
    env.execute("stream word count") //job的名字

  }

}
```

## 结果

使用nc命令往电脑的7777端口发送数据，程序会接收并处理数据。

```xml
nc -lk 7777
```



![](https://coachhe.oss-cn-shenzhen.aliyuncs.com/Scala/20210129041256.png)

### 注意

左边的7 4 2 4 4 表示并行的子任务个数













